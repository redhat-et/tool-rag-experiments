{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Data\n",
    "Format the data into a .pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to numpy.pt\n"
     ]
    }
   ],
   "source": [
    "!python libs/libraries/toolrag/mlc/format_train_data.py \\\n",
    "  --all_tools_path ./libs/libraries/all_tools.json \\\n",
    "  --train_data_path ./libs/libraries/NumpyBank_train.json \\\n",
    "  --output_path numpy.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "Note: This can be time consuming (~10min per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No wandb_name provided. Initializing Weights & Biases in 'disabled' mode.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Total number of batches per epoch: 250\n",
      "Epochs: 100%|████████████████████████████████| 10/10 [2:04:31<00:00, 747.16s/it]\n"
     ]
    }
   ],
   "source": [
    "!WANDB_MODE=disabled python libs/libraries/toolrag/mlc/train.py \\\n",
    "  --train_data_path numpy.pt \\\n",
    "  --valid_data_path libs/libraries/NumpyBank_val.json \\\n",
    "  --all_tools_path libs/libraries/all_tools.json \\\n",
    "  --checkpoint_dir numpy_checkpoints \\\n",
    "  --model_name bert-base-uncased \\\n",
    "  --epochs 10 \\\n",
    "  --num_labels 3145\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model performance\n",
    "Recall@3 meaning the recall score for the top 3 ranked tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Recall@3: 0.018910577243910577\n",
      "Recall@5: 0.029329329329329325\n",
      "Recall@7: 0.039881548214881546\n",
      "Recall@10: 0.057615949282615944\n",
      "Recall@12: 0.06608274941608275\n"
     ]
    }
   ],
   "source": [
    "!python libs/libraries/toolrag/mlc/test.py \\\n",
    "--test_data_path libs/libraries/NumpyBank_val.json \\\n",
    "--all_tools_path libs/libraries/all_tools.json \\\n",
    "--model_name bert-base-uncased \\\n",
    "--model_path numpy_checkpoints/model_recall_at_5.pt \\\n",
    "--num_labels 3145\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
